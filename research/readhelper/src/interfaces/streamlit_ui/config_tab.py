"""
é…ç½®é¡µé¢æ¨¡å—
"""

import streamlit as st
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from src.config.settings import settings
from src.core.ragflow_client import get_ragflow_client, RAGFlowConfig
from src.core.llm_client import get_llm_client, LLMConfig


def config_page():
    """é…ç½®é¡µé¢å†…å®¹"""
    st.title("âš™ï¸ ç³»ç»Ÿé…ç½®")
    
    # é…ç½®æ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs(["RAGFlowé…ç½®", "å¤§æ¨¡å‹é…ç½®", "ç³»ç»Ÿé…ç½®", "è¿æ¥æµ‹è¯•"])
    
    with tab1:
        ragflow_config_ui()
    
    with tab2:
        llm_config_ui()
    
    with tab3:
        system_config_ui()
    
    with tab4:
        connection_test_ui()


def ragflow_config_ui():
    """RAGFlowé…ç½®ç•Œé¢"""
    st.markdown("## ğŸ”— RAGFlowé…ç½®")
    
    st.markdown("### ğŸ“‹ è¿æ¥è®¾ç½®")
    
    col1, col2 = st.columns(2)
    
    with col1:
        ragflow_base_url = st.text_input(
            "RAGFlowæœåŠ¡å™¨åœ°å€",
            value=settings.ragflow_base_url,
            placeholder="http://localhost:9380",
            help="RAGFlowæœåŠ¡å™¨çš„URLåœ°å€"
        )
        
        ragflow_api_key = st.text_input(
            "RAGFlow APIå¯†é’¥",
            value=settings.ragflow_api_key,
            type="password",
            placeholder="è¾“å…¥æ‚¨çš„RAGFlow APIå¯†é’¥",
            help="ç”¨äºè®¿é—®RAGFlow APIçš„å¯†é’¥"
        )
    
    with col2:
        ragflow_timeout = st.number_input(
            "è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)",
            min_value=5,
            max_value=300,
            value=settings.ragflow_timeout,
            help="APIè¯·æ±‚çš„è¶…æ—¶æ—¶é—´"
        )
        
        ragflow_max_retries = st.number_input(
            "æœ€å¤§é‡è¯•æ¬¡æ•°",
            min_value=0,
            max_value=10,
            value=settings.ragflow_max_retries,
            help="APIè¯·æ±‚å¤±è´¥æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°"
        )
    
    # ä¿å­˜RAGFlowé…ç½®
    if st.button("ğŸ’¾ ä¿å­˜RAGFlowé…ç½®", key="save_ragflow"):
        save_ragflow_config(ragflow_base_url, ragflow_api_key, ragflow_timeout, ragflow_max_retries)
    
    # RAGFlowä½¿ç”¨è¯´æ˜
    with st.expander("ğŸ“– RAGFlowé…ç½®è¯´æ˜"):
        st.markdown("""
        ### RAGFlowæ˜¯ä»€ä¹ˆï¼Ÿ
        RAGFlowæ˜¯ä¸€ä¸ªå¼€æºçš„RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰å¼•æ“ï¼Œä¸“ä¸ºæ–‡çŒ®æ£€ç´¢å’Œé—®ç­”è®¾è®¡ã€‚
        
        ### å¦‚ä½•è·å–APIå¯†é’¥ï¼Ÿ
        1. å¯åŠ¨RAGFlowæœåŠ¡
        2. è®¿é—®RAGFlow Webç•Œé¢
        3. åœ¨è®¾ç½®æˆ–APIé¡µé¢ç”ŸæˆAPIå¯†é’¥
        4. å°†å¯†é’¥å¤åˆ¶åˆ°ä¸Šæ–¹è¾“å…¥æ¡†
        
        ### é»˜è®¤é…ç½®
        - æœ¬åœ°RAGFlowé»˜è®¤åœ°å€ï¼šhttp://localhost:9380
        - å¦‚æœä½¿ç”¨Dockeréƒ¨ç½²ï¼Œè¯·ç¡®ä¿ç«¯å£æ˜ å°„æ­£ç¡®
        - å¦‚æœä½¿ç”¨è¿œç¨‹æœåŠ¡ï¼Œè¯·è¾“å…¥å®Œæ•´çš„URLåœ°å€
        
        ### å¸¸è§é—®é¢˜
        - **è¿æ¥å¤±è´¥**ï¼šæ£€æŸ¥RAGFlowæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ
        - **è®¤è¯å¤±è´¥**ï¼šç¡®è®¤APIå¯†é’¥æ˜¯å¦æ­£ç¡®
        - **è¶…æ—¶é”™è¯¯**ï¼šå¢åŠ è¶…æ—¶æ—¶é—´æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥
        """)


def llm_config_ui():
    """å¤§æ¨¡å‹é…ç½®ç•Œé¢"""
    st.markdown("## ğŸ¤– å¤§æ¨¡å‹é…ç½®")
    
    st.markdown("### ğŸ“‹ æ¨¡å‹é€‰æ‹©")
    
    col1, col2 = st.columns(2)
    
    with col1:
        llm_provider = st.selectbox(
            "å¤§æ¨¡å‹æä¾›å•†",
            ["openai", "qwen", "claude", "local"],
            index=["openai", "qwen", "claude", "local"].index(settings.llm_provider),
            help="é€‰æ‹©æ‚¨è¦ä½¿ç”¨çš„å¤§æ¨¡å‹æä¾›å•†"
        )
        
        llm_api_key = st.text_input(
            "APIå¯†é’¥",
            value=settings.llm_api_key,
            type="password",
            placeholder="è¾“å…¥æ‚¨çš„APIå¯†é’¥",
            help=f"{llm_provider.upper()}çš„APIå¯†é’¥"
        )
    
    with col2:
        llm_base_url = st.text_input(
            "APIåŸºç¡€URL",
            value=settings.llm_base_url,
            placeholder="è‡ªåŠ¨æ ¹æ®æä¾›å•†è®¾ç½®",
            help="APIçš„åŸºç¡€URLï¼Œç•™ç©ºåˆ™ä½¿ç”¨é»˜è®¤åœ°å€"
        )
        
        llm_model = st.text_input(
            "æ¨¡å‹åç§°",
            value=settings.llm_model,
            placeholder="è‡ªåŠ¨æ ¹æ®æä¾›å•†è®¾ç½®",
            help="è¦ä½¿ç”¨çš„å…·ä½“æ¨¡å‹åç§°"
        )
    
    st.markdown("### âš™ï¸ æ¨¡å‹å‚æ•°")
    
    col3, col4 = st.columns(2)
    
    with col3:
        llm_temperature = st.slider(
            "æ¸©åº¦å‚æ•°",
            min_value=0.0,
            max_value=2.0,
            value=settings.llm_temperature,
            step=0.1,
            help="æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ï¼Œè¶Šé«˜è¶Šéšæœº"
        )
        
        llm_max_tokens = st.number_input(
            "æœ€å¤§Tokenæ•°",
            min_value=100,
            max_value=8192,
            value=settings.llm_max_tokens,
            step=100,
            help="ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦"
        )
    
    with col4:
        llm_timeout = st.number_input(
            "è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)",
            min_value=10,
            max_value=600,
            value=settings.llm_timeout,
            help="APIè¯·æ±‚çš„è¶…æ—¶æ—¶é—´"
        )
        
        llm_max_retries = st.number_input(
            "æœ€å¤§é‡è¯•æ¬¡æ•°",
            min_value=0,
            max_value=10,
            value=settings.llm_max_retries,
            help="APIè¯·æ±‚å¤±è´¥æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°"
        )
    
    # ä¿å­˜å¤§æ¨¡å‹é…ç½®
    if st.button("ğŸ’¾ ä¿å­˜å¤§æ¨¡å‹é…ç½®", key="save_llm"):
        save_llm_config(llm_provider, llm_api_key, llm_base_url, llm_model, 
                      llm_temperature, llm_max_tokens, llm_timeout, llm_max_retries)
    
    # æ¨¡å‹æä¾›å•†è¯´æ˜
    with st.expander("ğŸ“– å¤§æ¨¡å‹æä¾›å•†è¯´æ˜"):
        st.markdown("""
        ### OpenAI
        - **æ¨¡å‹**: gpt-3.5-turbo, gpt-4, gpt-4-turbo
        - **APIå¯†é’¥**: ä»OpenAIå®˜ç½‘è·å–
        - **é€‚ç”¨åœºæ™¯**: é€šç”¨é—®ç­”ã€æ–‡æœ¬ç”Ÿæˆ
        
        ### é€šä¹‰åƒé—®
        - **æ¨¡å‹**: qwen-turbo, qwen-plus, qwen-max
        - **APIå¯†é’¥**: ä»é˜¿é‡Œäº‘DashScopeè·å–
        - **é€‚ç”¨åœºæ™¯**: ä¸­æ–‡å¤„ç†ã€ä¸“ä¸šé¢†åŸŸ
        
        ### Claude
        - **æ¨¡å‹**: claude-3-sonnet, claude-3-opus, claude-3-haiku
        - **APIå¯†é’¥**: ä»Anthropicå®˜ç½‘è·å–
        - **é€‚ç”¨åœºæ™¯**: é•¿æ–‡æœ¬å¤„ç†ã€å¤æ‚æ¨ç†
        
        ### æœ¬åœ°æ¨¡å‹
        - **æ¨¡å‹**: é€šè¿‡Ollamaéƒ¨ç½²çš„æ¨¡å‹
        - **APIå¯†é’¥**: é€šå¸¸ä¸éœ€è¦
        - **é€‚ç”¨åœºæ™¯**: ç¦»çº¿ä½¿ç”¨ã€æ•°æ®éšç§
        
        ### æ¨èé…ç½®
        - **æ–‡çŒ®æ‘˜è¦**: æ¸©åº¦0.3-0.5ï¼Œæœ€å¤§Token 1000-1500
        - **å…³é”®è¯æå–**: æ¸©åº¦0.1-0.3ï¼Œæœ€å¤§Token 500-800
        - **è¶‹åŠ¿åˆ†æ**: æ¸©åº¦0.5-0.7ï¼Œæœ€å¤§Token 1500-2000
        """)


def system_config_ui():
    """ç³»ç»Ÿé…ç½®ç•Œé¢"""
    st.markdown("## ğŸ–¥ï¸ ç³»ç»Ÿé…ç½®")
    
    st.markdown("### ğŸ“„ æ–‡æ¡£å¤„ç†")
    
    col1, col2 = st.columns(2)
    
    with col1:
        max_pdf_size = st.number_input(
            "æœ€å¤§PDFæ–‡ä»¶å¤§å°(MB)",
            min_value=1,
            max_value=100,
            value=settings.max_pdf_size // (1024*1024),
            help="å…è®¸ä¸Šä¼ çš„PDFæ–‡ä»¶æœ€å¤§å¤§å°"
        )
        
        auto_extract_metadata = st.checkbox(
            "è‡ªåŠ¨æå–å…ƒæ•°æ®",
            value=settings.auto_extract_metadata,
            help="æ˜¯å¦è‡ªåŠ¨ä»æ–‡æ¡£ä¸­æå–å…ƒæ•°æ®"
        )
    
    with col2:
        summary_max_length = st.number_input(
            "æ‘˜è¦æœ€å¤§é•¿åº¦",
            min_value=100,
            max_value=2000,
            value=settings.summary_max_length,
            step=50,
            help="ç”Ÿæˆæ‘˜è¦çš„æœ€å¤§å­—ç¬¦æ•°"
        )
        
        keywords_max_count = st.number_input(
            "å…³é”®è¯æœ€å¤§æ•°é‡",
            min_value=5,
            max_value=20,
            value=settings.keywords_max_count,
            help="æå–å…³é”®è¯çš„æœ€å¤§æ•°é‡"
        )
    
    st.markdown("### ğŸ” æœç´¢è®¾ç½®")
    
    col3, col4 = st.columns(2)
    
    with col3:
        search_results_limit = st.number_input(
            "æœç´¢ç»“æœé™åˆ¶",
            min_value=5,
            max_value=50,
            value=settings.search_results_limit,
            help="é»˜è®¤è¿”å›çš„æœç´¢ç»“æœæ•°é‡"
        )
        
        similarity_threshold = st.slider(
            "ç›¸ä¼¼åº¦é˜ˆå€¼",
            min_value=0.0,
            max_value=1.0,
            value=settings.similarity_threshold,
            step=0.05,
            help="ç­›é€‰ç›¸å…³æ–‡æ¡£çš„ç›¸ä¼¼åº¦é˜ˆå€¼"
        )
    
    with col4:
        semantic_search_enabled = st.checkbox(
            "å¯ç”¨è¯­ä¹‰æœç´¢",
            value=settings.semantic_search_enabled,
            help="æ˜¯å¦å¯ç”¨åŸºäºè¯­ä¹‰çš„æœç´¢åŠŸèƒ½"
        )
        
        cache_enabled = st.checkbox(
            "å¯ç”¨ç¼“å­˜",
            value=settings.cache_enabled,
            help="æ˜¯å¦å¯ç”¨ç»“æœç¼“å­˜ä»¥æé«˜æ€§èƒ½"
        )
    
    st.markdown("### â›ï¸ æ–‡çŒ®æŒ–æ˜")
    
    col5, col6 = st.columns(2)
    
    with col5:
        mining_max_docs = st.number_input(
            "æŒ–æ˜æœ€å¤§æ–‡æ¡£æ•°",
            min_value=10,
            max_value=100,
            value=settings.mining_max_docs,
            step=10,
            help="æ–‡çŒ®æŒ–æ˜æ—¶ä½¿ç”¨çš„æœ€å¤§æ–‡æ¡£æ•°é‡"
        )
        
        mining_similarity_threshold = st.slider(
            "æŒ–æ˜ç›¸ä¼¼åº¦é˜ˆå€¼",
            min_value=0.5,
            max_value=0.9,
            value=settings.mining_similarity_threshold,
            step=0.05,
            help="æ–‡çŒ®æŒ–æ˜æ—¶ç­›é€‰æ–‡æ¡£çš„ç›¸ä¼¼åº¦é˜ˆå€¼"
        )
    
    with col6:
        mining_summary_length = st.selectbox(
            "æ‘˜è¦é•¿åº¦",
            ["ç®€çŸ­", "ä¸­ç­‰é•¿åº¦", "è¯¦ç»†"],
            index=["ç®€çŸ­", "ä¸­ç­‰é•¿åº¦", "è¯¦ç»†"].index(settings.mining_summary_length),
            help="æ–‡çŒ®æŒ–æ˜æ—¶ç”Ÿæˆæ‘˜è¦çš„é•¿åº¦"
        )
        
        page_size = st.number_input(
            "é¡µé¢å¤§å°",
            min_value=5,
            max_value=50,
            value=settings.page_size,
            help="åˆ†é¡µæ˜¾ç¤ºæ—¶æ¯é¡µçš„é¡¹ç›®æ•°é‡"
        )
    
    # ä¿å­˜ç³»ç»Ÿé…ç½®
    if st.button("ğŸ’¾ ä¿å­˜ç³»ç»Ÿé…ç½®", key="save_system"):
        save_system_config(
            max_pdf_size, auto_extract_metadata, summary_max_length, keywords_max_count,
            search_results_limit, similarity_threshold, semantic_search_enabled, cache_enabled,
            mining_max_docs, mining_similarity_threshold, mining_summary_length, page_size
        )
    
    # é…ç½®è¯´æ˜
    with st.expander("ğŸ“– ç³»ç»Ÿé…ç½®è¯´æ˜"):
        st.markdown("""
        ### æ–‡æ¡£å¤„ç†è®¾ç½®
        - **PDFå¤§å°é™åˆ¶**: é˜²æ­¢ä¸Šä¼ è¿‡å¤§æ–‡ä»¶å¯¼è‡´ç³»ç»Ÿé—®é¢˜
        - **å…ƒæ•°æ®æå–**: è‡ªåŠ¨ä»æ–‡æ¡£ä¸­æå–æ ‡é¢˜ã€ä½œè€…ç­‰ä¿¡æ¯
        - **æ‘˜è¦é•¿åº¦**: æ§åˆ¶ç”Ÿæˆæ‘˜è¦çš„è¯¦ç»†ç¨‹åº¦
        - **å…³é”®è¯æ•°é‡**: æå–çš„å…³é”®è¯æ•°é‡ï¼Œå½±å“åˆ†æç²¾åº¦
        
        ### æœç´¢è®¾ç½®
        - **ç»“æœé™åˆ¶**: æ§åˆ¶è¿”å›çš„æœç´¢ç»“æœæ•°é‡ï¼Œå½±å“å“åº”é€Ÿåº¦
        - **ç›¸ä¼¼åº¦é˜ˆå€¼**: ç­›é€‰ç›¸å…³æ–‡æ¡£çš„ä¸¥æ ¼ç¨‹åº¦
        - **è¯­ä¹‰æœç´¢**: åŸºäºå†…å®¹ç†è§£è€Œéå…³é”®è¯åŒ¹é…
        - **ç¼“å­˜**: ç¼“å­˜æœç´¢ç»“æœä»¥æé«˜å“åº”é€Ÿåº¦
        
        ### æ–‡çŒ®æŒ–æ˜è®¾ç½®
        - **æ–‡æ¡£æ•°é‡**: æŒ–æ˜åˆ†æçš„æ–‡æ¡£æ•°é‡ï¼Œå½±å“åˆ†ææ·±åº¦å’Œé€Ÿåº¦
        - **ç›¸ä¼¼åº¦é˜ˆå€¼**: ç­›é€‰ç›¸å…³æ–‡æ¡£çš„é˜ˆå€¼
        - **æ‘˜è¦é•¿åº¦**: æŒ–æ˜åˆ†ææ—¶ç”Ÿæˆæ‘˜è¦çš„è¯¦ç»†ç¨‹åº¦
        - **é¡µé¢å¤§å°**: ç•Œé¢åˆ†é¡µæ˜¾ç¤ºçš„é¡¹ç›®æ•°é‡
        """)


def connection_test_ui():
    """è¿æ¥æµ‹è¯•ç•Œé¢"""
    st.markdown("## ğŸ”§ è¿æ¥æµ‹è¯•")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ”— RAGFlowè¿æ¥æµ‹è¯•")
        
        if st.button("ğŸ” æµ‹è¯•RAGFlowè¿æ¥", key="test_ragflow"):
            test_ragflow_connection()
    
    with col2:
        st.markdown("### ğŸ¤– å¤§æ¨¡å‹è¿æ¥æµ‹è¯•")
        
        if st.button("ğŸ” æµ‹è¯•å¤§æ¨¡å‹è¿æ¥", key="test_llm"):
            test_llm_connection()
    
    st.markdown("---")
    st.markdown("### ğŸ“Š é…ç½®çŠ¶æ€")
    
    # æ˜¾ç¤ºå½“å‰é…ç½®çŠ¶æ€
    config_validation = settings.validate_config()
    
    if config_validation['valid']:
        st.success("âœ… é…ç½®éªŒè¯é€šè¿‡")
    else:
        st.error("âŒ é…ç½®å­˜åœ¨é—®é¢˜")
    
    # RAGFlowé…ç½®çŠ¶æ€
    ragflow_configured = settings.is_ragflow_configured()
    if ragflow_configured:
        st.success("âœ… RAGFlowé…ç½®å®Œæ•´")
    else:
        st.error("âŒ RAGFlowé…ç½®ä¸å®Œæ•´")
    
    # å¤§æ¨¡å‹é…ç½®çŠ¶æ€
    llm_configured = settings.is_llm_configured()
    if llm_configured:
        st.success("âœ… å¤§æ¨¡å‹é…ç½®å®Œæ•´")
    else:
        st.error("âŒ å¤§æ¨¡å‹é…ç½®ä¸å®Œæ•´")
    
    # æ˜¾ç¤ºé…ç½®é—®é¢˜
    if config_validation['issues']:
        st.markdown("#### âš ï¸ é…ç½®é—®é¢˜")
        for issue in config_validation['issues']:
            st.error(f"- {issue}")
    
    if config_validation['warnings']:
        st.markdown("#### âš ï¸ é…ç½®è­¦å‘Š")
        for warning in config_validation['warnings']:
            st.warning(f"- {warning}")


def save_ragflow_config(base_url, api_key, timeout, max_retries):
    """ä¿å­˜RAGFlowé…ç½®"""
    try:
        # æ›´æ–°è®¾ç½®
        settings.ragflow_base_url = base_url
        settings.ragflow_api_key = api_key
        settings.ragflow_timeout = timeout
        settings.ragflow_max_retries = max_retries
        
        # é‡æ–°åˆ›å»ºå®¢æˆ·ç«¯
        ragflow_config = RAGFlowConfig(**settings.get_ragflow_config())
        st.session_state.ragflow_client = get_ragflow_client(ragflow_config)
        
        st.success("RAGFlowé…ç½®å·²ä¿å­˜")
    except Exception as e:
        st.error(f"ä¿å­˜RAGFlowé…ç½®å¤±è´¥: {e}")


def save_llm_config(provider, api_key, base_url, model, temperature, max_tokens, timeout, max_retries):
    """ä¿å­˜å¤§æ¨¡å‹é…ç½®"""
    try:
        # æ›´æ–°è®¾ç½®
        settings.llm_provider = provider
        settings.llm_api_key = api_key
        settings.llm_base_url = base_url
        settings.llm_model = model
        settings.llm_temperature = temperature
        settings.llm_max_tokens = max_tokens
        settings.llm_timeout = timeout
        settings.llm_max_retries = max_retries
        
        # é‡æ–°åˆ›å»ºå®¢æˆ·ç«¯
        llm_config = LLMConfig(**settings.get_llm_config())
        st.session_state.llm_client = get_llm_client(llm_config)
        
        st.success("å¤§æ¨¡å‹é…ç½®å·²ä¿å­˜")
    except Exception as e:
        st.error(f"ä¿å­˜å¤§æ¨¡å‹é…ç½®å¤±è´¥: {e}")


def save_system_config(max_pdf_size, auto_extract_metadata, summary_max_length, keywords_max_count,
                     search_results_limit, similarity_threshold, semantic_search_enabled, cache_enabled,
                     mining_max_docs, mining_similarity_threshold, mining_summary_length, page_size):
    """ä¿å­˜ç³»ç»Ÿé…ç½®"""
    try:
        # æ›´æ–°è®¾ç½®
        settings.max_pdf_size = max_pdf_size * 1024 * 1024  # è½¬æ¢ä¸ºå­—èŠ‚
        settings.auto_extract_metadata = auto_extract_metadata
        settings.summary_max_length = summary_max_length
        settings.keywords_max_count = keywords_max_count
        settings.search_results_limit = search_results_limit
        settings.similarity_threshold = similarity_threshold
        settings.semantic_search_enabled = semantic_search_enabled
        settings.cache_enabled = cache_enabled
        settings.mining_max_docs = mining_max_docs
        settings.mining_similarity_threshold = mining_similarity_threshold
        settings.mining_summary_length = mining_summary_length
        settings.page_size = page_size
        
        st.success("ç³»ç»Ÿé…ç½®å·²ä¿å­˜")
    except Exception as e:
        st.error(f"ä¿å­˜ç³»ç»Ÿé…ç½®å¤±è´¥: {e}")


def test_ragflow_connection():
    """æµ‹è¯•RAGFlowè¿æ¥"""
    with st.spinner("æ­£åœ¨æµ‹è¯•RAGFlowè¿æ¥..."):
        try:
            health = st.session_state.ragflow_client.health_check()
            
            if health.get("status") == "healthy":
                st.success("âœ… RAGFlowè¿æ¥æˆåŠŸ")
                st.json(health)
            else:
                st.error("âŒ RAGFlowè¿æ¥å¤±è´¥")
                if "error" in health:
                    st.error(f"é”™è¯¯ä¿¡æ¯: {health['error']}")
        except Exception as e:
            st.error(f"âŒ RAGFlowè¿æ¥æµ‹è¯•å¤±è´¥: {e}")


def test_llm_connection():
    """æµ‹è¯•å¤§æ¨¡å‹è¿æ¥"""
    with st.spinner("æ­£åœ¨æµ‹è¯•å¤§æ¨¡å‹è¿æ¥..."):
        try:
            from src.core.llm_client import Message
            
            # å‘é€æµ‹è¯•æ¶ˆæ¯
            messages = [
                Message(role="system", content="ä½ æ˜¯ä¸€ä¸ªæµ‹è¯•åŠ©æ‰‹"),
                Message(role="user", content="è¯·å›å¤'è¿æ¥æˆåŠŸ'")
            ]
            
            response = st.session_state.llm_client.chat(messages)
            
            if response.content and "è¿æ¥æˆåŠŸ" in response.content:
                st.success("âœ… å¤§æ¨¡å‹è¿æ¥æˆåŠŸ")
                st.text_area("æ¨¡å‹å›å¤", response.content, height=100, disabled=True)
            else:
                st.warning("âš ï¸ å¤§æ¨¡å‹è¿æ¥å¼‚å¸¸")
                st.text_area("æ¨¡å‹å›å¤", response.content, height=100, disabled=True)
        except Exception as e:
            st.error(f"âŒ å¤§æ¨¡å‹è¿æ¥æµ‹è¯•å¤±è´¥: {e}")